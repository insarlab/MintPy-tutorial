{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series analysis of hyp3 InSAR products by MintPy\n",
    "\n",
    "This notebook shows how to do time-series analysis with HyP3 InSAR product by MintPy. We assume you have already got the hyp3 InSAR products somewhere. This steps for the analysis are: clip the hyp3 INSAR product, define the config.txt file, run the time series analysis, and display the results. We use 2019 Ridgecrest Earthquake, CA (https://earthquake.usgs.gov/storymap/index-ridgecrest.html) as the example. The example hyp3 INSAR data are at https://jzhu-hyp3-dev.s3.us-west-2.amazonaws.com/hyp3-mintpy-example/2019_ridgecrest.zip. As far as how to produce the hyp3 INSAR product, we provide the detail steps in the tutorial(https://github.com/ASFHyP3/hyp3-docs/blob/develop/docs/tutorials/hyp3_insar_stack_for_ts_analysis.ipynb). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initial setup of the notebook\n",
    "\n",
    "To run this notebook, you'll need a conda environment with the required dependencies. You can set up a new environment (recommended) and run the jupyter server like:\n",
    "\n",
    "conda create -n hyp3-mintpy python=3.8 asf_search hyp3_sdk \"mintpy>=1.3.2\" pandas jupyter ipympl\n",
    "\n",
    "To make you conda env accessible in the jupyter notebook, you need to do:\n",
    "\n",
    "conda activate hyp3-mintpy\n",
    "conda install -c conda-forge tensorflow\n",
    "conda install -c anaconda ipykernel\n",
    "python -m ipykernel install --user --name=hyp3-mintpy\n",
    "\n",
    "To run your notebook, just:\n",
    "\n",
    "conda activate hyp3-mintpy\n",
    "jupyter notebook smallbaselineApp_hyp3_new.ipynb\n",
    "\n",
    "For your convinience, we provide the ERA5 data at https://jzhu-hyp3-dev.s3.us-west-2.amazonaws.com/hyp3-mintpy-example/2019_ridgecrest_era5_data.zip, you can download the and unzip the file to the 'your_weather_dir' directory on you local machine, and setup the environment variable. e.g. export WEATHER_DIR='your_weather_dir'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters and create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_name = 'Ridgecrest'\n",
    "\n",
    "work_dir = Path.cwd() / project_name\n",
    "\n",
    "data_dir = work_dir / 'data'\n",
    "\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run MintPy routine workflow `smallbaselineApp.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the hyp3 InSAR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example dataset is from 2019 Ridgecrest Earthquake, CA. The dataset can be obtained through either downloading from the stagged server or producing with hyp3-sdk. Here we provide the sample dataset at  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '2019_ridgecrest.zip'\n",
    "\n",
    "file_url = f'https://jzhu-hyp3-dev.s3.us-west-2.amazonaws.com/hyp3-mintpy-example/{file}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget {file_url} -P {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'downloaded file is {data_dir}/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def unzip_files(zip_file, data_dir):\n",
    "    if os.path.isfile(zip_file):\n",
    "        with zipfile.ZipFile(zip_file, 'r') as fzip:\n",
    "            fzip.extractall(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_files(f'{data_dir}/{file}', data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cut geotiff files for mintpy analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the minumum overlap of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "def get_minimum_overlap(filelist: List[Union[str, Path]]) -> List[float]:\n",
    "    \"\"\"Get the minimum overlap of the geotiff files in the filelist.\n",
    "    \n",
    "    Arg:\n",
    "        filelist: a list of geotiff file names. The file names can be strings or Path objects.\n",
    "    \n",
    "    Returns:\n",
    "         [ulx, uly, lrx, lry], a list which includes the upper-left x, upper-left y, lower-right x, \n",
    "         and lower-right y.\n",
    "    \"\"\"\n",
    "    corners = [gdal.Info(str(dem), format='json')['cornerCoordinates'] for dem in filelist]\n",
    "\n",
    "    ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "    uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "    lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "    lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "    return [ulx, uly, lrx, lry]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = data_dir.glob('*/*_dem.tif')\n",
    "\n",
    "overlap = get_minimum_overlap(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clip the files with overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, Path\n",
    "from typing import List, Union\n",
    "\n",
    "def clip_hyp3_products_to_minimum_overlap(data_dir: Union[str, Path], overlap: List[float]) -> None:\n",
    "    \"\"\"Clip all geotiff files in the directory with the overlap.\n",
    "    \n",
    "    Args:\n",
    "        data_dir:\n",
    "            name of a directory which includes the geotiff files.\n",
    "        overlap:\n",
    "            a list which includes the upper-left x, upper-left y, lower-right-x, and lower-tight y.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "\n",
    "    files_for_mintpy = ['_water_mask.tif', '_corr.tif', '_unw_phase.tif', '_dem.tif', '_lv_theta.tif', '_lv_phi.tif']\n",
    "\n",
    "    for extension in files_for_mintpy:\n",
    "\n",
    "        for file in data_dir.rglob(f'*{extension}'):\n",
    "\n",
    "            dst_file = file.parent / f'{file.stem}_clipped{file.suffix}'\n",
    "\n",
    "            gdal.Translate(destName=str(dst_file), srcDS=str(file), projWin=overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_hyp3_products_to_minimum_overlap(data_dir, overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Prepare the template file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mintpy_config = work_dir / 'mintpy_config.txt'\n",
    "mintpy_config.write_text(\n",
    "f\"\"\"\n",
    "mintpy.load.processor        = hyp3\n",
    "##---------interferogram datasets:\n",
    "mintpy.load.unwFile          = {data_dir}/*/*_unw_phase_clipped.tif\n",
    "mintpy.load.corFile          = {data_dir}/*/*_corr_clipped.tif\n",
    "##---------geometry datasets:\n",
    "mintpy.load.demFile          = {data_dir}/*/*_dem_clipped.tif\n",
    "mintpy.load.incAngleFile     = {data_dir}/*/*_lv_theta_clipped.tif\n",
    "mintpy.load.azAngleFile      = {data_dir}/*/*_lv_phi_clipped.tif\n",
    "mintpy.load.waterMaskFile    = {data_dir}/*/*_water_mask_clipped.tif\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Run Time-series Analysis application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! smallbaselineApp.py --work-dir {work_dir}  {mintpy_config}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Display the analysis results\n",
    "\n",
    "There are a few scripts used to display the analysis results. There are in the MINTPY_HOME/mintpy. Here we show two majoy disaply scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from mintpy import view, tsview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view.main([f'{work_dir}/velocity.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsview.main([f'{work_dir}/timeseries.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyp3-mintpy",
   "language": "python",
   "name": "hyp3-mintpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

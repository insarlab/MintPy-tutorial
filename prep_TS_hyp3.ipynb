{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InSAR time series analysis with HyP3 and MintPy\n",
    "\n",
    "This notebook shows how to do time-series analysis using HyP3 product with MintPy. It requires `hyp3_sdk` and `MintPy`:\n",
    "\n",
    "+ run `conda install --yes -c conda-forge hyp3_sdk ipywidgets` to install `hyp3_sdk`\n",
    "+ check the [installation page](https://github.com/insarlab/MintPy/blob/main/docs/installation.md) to install `MintPy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initial setup of the notebook\n",
    "\n",
    "The cell below performs the intial setup of the notebook and must be **run every time the notebook (re)starts**. It imports necessary modules and defines the processing location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import hyp3_sdk as sdk\n",
    "from pathlib import Path\n",
    "from osgeo import gdal\n",
    "from mintpy import view, tsview\n",
    "proj_dir = os.path.expanduser('~/data/test/Ridgecrest')\n",
    "proj_name = os.path.basename(proj_dir)\n",
    "hyp3_dir = os.path.join(proj_dir, 'hyp3')\n",
    "mintpy_dir = os.path.join(proj_dir, 'mintpy')\n",
    "os.makedirs(hyp3_dir, exist_ok=True)\n",
    "os.makedirs(mintpy_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set project name, output directory and change to the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectname = input(\"project name:\") or \"case5\"\n",
    "outdir = input(\"home directory of the project\") or \"./tutorial\"\n",
    "os.system(\"mkdir -p {}\".format(outdir))\n",
    "print(projectname)\n",
    "print(outdir)\n",
    "os.chdir(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the hyp3 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of the granule pairs include the granule pairs that users want to use them to produce the interferograms for the time-series analysis purpose. Users usually prepare this list through the ASF vertex (https://serach.asf.alaska.edu). For example, we analysis the 2019 Ridgecrest earthquakes with the list of the granule pairs as defined in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "  ('S1A_IW_SLC__1SDV_20190610T135156_20190610T135223_027618_031DEF_C70F', 'S1A_IW_SLC__1SDV_20190622T135157_20190622T135224_027793_03232E_0388'),\n",
    "  ('S1A_IW_SLC__1SDV_20190610T135156_20190610T135223_027618_031DEF_C70F', 'S1A_IW_SLC__1SDV_20190704T135158_20190704T135225_027968_032877_1C4D'),\n",
    "  ('S1A_IW_SLC__1SDV_20190622T135157_20190622T135224_027793_03232E_0388', 'S1A_IW_SLC__1SDV_20190704T135158_20190704T135225_027968_032877_1C4D'),\n",
    "  ('S1A_IW_SLC__1SDV_20190622T135157_20190622T135224_027793_03232E_0388', 'S1A_IW_SLC__1SDV_20190716T135159_20190716T135226_028143_032DC3_512B'),\n",
    "  ('S1A_IW_SLC__1SDV_20190704T135158_20190704T135225_027968_032877_1C4D', 'S1A_IW_SLC__1SDV_20190716T135159_20190716T135226_028143_032DC3_512B'),\n",
    "  ('S1A_IW_SLC__1SDV_20190704T135158_20190704T135225_027968_032877_1C4D', 'S1A_IW_SLC__1SDV_20190728T135159_20190728T135226_028318_03331A_C807'),\n",
    "  ('S1A_IW_SLC__1SDV_20190716T135159_20190716T135226_028143_032DC3_512B', 'S1A_IW_SLC__1SDV_20190728T135159_20190728T135226_028318_03331A_C807'),\n",
    "  ('S1A_IW_SLC__1SDV_20190716T135159_20190716T135226_028143_032DC3_512B', 'S1A_IW_SLC__1SDV_20190809T135200_20190809T135227_028493_033887_08A4'),\n",
    "  ('S1A_IW_SLC__1SDV_20190728T135159_20190728T135226_028318_03331A_C807', 'S1A_IW_SLC__1SDV_20190809T135200_20190809T135227_028493_033887_08A4'),\n",
    "  ('S1A_IW_SLC__1SDV_20190728T135159_20190728T135226_028318_03331A_C807', 'S1A_IW_SLC__1SDV_20190821T135201_20190821T135228_028668_033EA0_ADF7'),\n",
    "  ('S1A_IW_SLC__1SDV_20190809T135200_20190809T135227_028493_033887_08A4', 'S1A_IW_SLC__1SDV_20190821T135201_20190821T135228_028668_033EA0_ADF7'),\n",
    "  ('S1A_IW_SLC__1SDV_20190809T135200_20190809T135227_028493_033887_08A4', 'S1B_IW_SLC__1SDV_20190815T135119_20190815T135146_017597_0211A9_DE22'),\n",
    "  ('S1A_IW_SLC__1SDV_20190821T135201_20190821T135228_028668_033EA0_ADF7', 'S1B_IW_SLC__1SDV_20190815T135119_20190815T135146_017597_0211A9_DE22'),\n",
    "  ('S1A_IW_SLC__1SDV_20190821T135201_20190821T135228_028668_033EA0_ADF7', 'S1B_IW_SLC__1SDV_20190827T135119_20190827T135146_017772_021724_4F37'),\n",
    "  ('S1B_IW_SLC__1SDV_20190815T135119_20190815T135146_017597_0211A9_DE22', 'S1B_IW_SLC__1SDV_20190827T135119_20190827T135146_017772_021724_4F37'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Run 'hyp3_sdk' application to submit jobs for InSAR processing and to download the hyp3 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(hyp3_dir)\n",
    "print('Go to directory:', hyp3_dir)\n",
    "\n",
    "# initiate HyP3 object\n",
    "hyp3 = sdk.HyP3(prompt = True)\n",
    "insar_jobs = sdk.Batch()\n",
    "\n",
    "# submit InSAR jobs\n",
    "for pair in pairs:\n",
    "    reference_granule = pair[0]\n",
    "    secondary_granule = pair[1]\n",
    "    insar_jobs += hyp3.submit_insar_job(reference_granule, secondary_granule,\n",
    "                                        name=projectname, include_inc_map=True,\n",
    "                                        include_dem=True)\n",
    "# watch InSAR jobs\n",
    "insar_jobs = hyp3.watch(insar_jobs)\n",
    "\n",
    "# download and uncompress InSAR results\n",
    "zip_files = insar_jobs.download_files()\n",
    "\n",
    "for zip_file in zip_files:\n",
    "    with zipfile.ZipFile(zip_file) as zip_ref:\n",
    "        zip_ref.extractall(hyp3_dir)\n",
    "\n",
    "# prepared data structure are:\n",
    "! tree {hyp3_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare InSAR files for MintPy time series analysis\n",
    "\n",
    "By clipping the GeoTIFF files into the same grids using `gdal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob.glob(os.path.join(hyp3_dir, '*/*.tif'))\n",
    "\n",
    "# determine the smallest area covered by all input files\n",
    "corners = [gdal.Info(f, format='json')['cornerCoordinates'] for f in fnames]\n",
    "ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "\n",
    "# subset all input files to these common coordinates\n",
    "for fname in fnames:\n",
    "    fname_out = fname.replace('.tif', '_clip.tif')\n",
    "    gdal.Translate(destName=fname_out, srcDS=fname, projWin=[ulx, uly, lrx, lry])\n",
    "\n",
    "# show the data structure\n",
    "! tree {hyp3_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run MintPy routine workflow `smallbaselineApp.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Prepare the template file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_txt = f'''\n",
    "mintpy.load.processor        = hyp3\n",
    "##---------interferogram datasets:\n",
    "mintpy.load.unwFile          = {hyp3_dir}/*/*unw_phase_clip.tif\n",
    "mintpy.load.corFile          = {hyp3_dir}/*/*corr_clip.tif\n",
    "##---------geometry datasets:\n",
    "mintpy.load.demFile          = {hyp3_dir}/*/*dem_clip.tif\n",
    "mintpy.load.incAngleFile     = {hyp3_dir}/*/*inc_map_clip.tif\n",
    "'''\n",
    "\n",
    "# write to file\n",
    "config_file = os.path.join(mintpy_dir, f'{proj_name}.txt')\n",
    "with open(config_file, 'w') as fid:\n",
    "    fid.write(config_txt)\n",
    "print('write file:', config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Run Time-series Analysis application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! smallbaselineApp.py {config_file} --work-dir {mintpy_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Display the analysis results\n",
    "\n",
    "There are a few scripts used to display the analysis results. There are in the MINTPY_HOME/mintpy. Here we show two majoy disaply scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main(['mintpy/velocity.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsview.main(['mintpy/timeseries.h5'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

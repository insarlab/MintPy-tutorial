{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InSAR time series analysis with HyP3 and MintPy\n",
    "\n",
    "This notebook shows how to do time-series analysis using HyP3 product with MintPy. It requires `hyp3_sdk` and `MintPy`:\n",
    "\n",
    "+ run `conda install --yes -c conda-forge hyp3_sdk ipywidgets` to install `hyp3_sdk`\n",
    "+ check the [installation page](https://github.com/insarlab/MintPy/blob/main/docs/installation.md) to install `MintPy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initial setup of the notebook\n",
    "\n",
    "The cell below performs the intial setup of the notebook and must be **run every time the notebook (re)starts**. It imports necessary modules and defines the processing location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import hyp3_sdk as sdk\n",
    "from pathlib import Path\n",
    "from osgeo import gdal\n",
    "from mintpy import view, tsview\n",
    "\n",
    "proj_dir = os.path.expanduser('~/data/test/HonshuSenDT119')\n",
    "proj_name = os.path.basename(proj_dir)\n",
    "hyp3_dir = os.path.join(proj_dir, 'hyp3')\n",
    "mintpy_dir = os.path.join(proj_dir, 'mintpy')\n",
    "\n",
    "os.makedirs(hyp3_dir, exist_ok=True)\n",
    "os.makedirs(mintpy_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Search SLC filenames\n",
    "\n",
    "Get the SLC filenames to be used for InSAR processing with HyP3. \n",
    "\n",
    "One could use the ASF vertex (https://serach.asf.alaska.edu) for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_granule = 'S1A_IW_SLC__1SSV_20160112T205113_20160112T205140_009466_00DBA8_C430'\n",
    "\n",
    "secondary_granules = [\n",
    "    'S1A_IW_SLC__1SSV_20160205T205112_20160205T205139_009816_00E5D1_997E',\n",
    "    'S1A_IW_SLC__1SSV_20160229T205112_20160229T205139_010166_00EFF4_357E',\n",
    "    'S1A_IW_SLC__1SSV_20160324T205112_20160324T205139_010516_00F9E8_FA1C',\n",
    "    'S1A_IW_SLC__1SSV_20160417T205113_20160417T205140_010866_010443_7429',\n",
    "    'S1A_IW_SLC__1SSV_20160511T205115_20160511T205142_011216_010F42_BD06',\n",
    "    'S1A_IW_SLC__1SSV_20160604T205107_20160604T205135_011566_011A9C_EDD4',\n",
    "    'S1A_IW_SLC__1SSV_20160628T205108_20160628T205136_011916_01259C_EE11'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run `hyp3_sdk` application\n",
    "\n",
    "+ to submit jobs for InSAR processing and \n",
    "+ to download the hyp3 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(hyp3_dir)\n",
    "print('Go to directory:', hyp3_dir)\n",
    "\n",
    "# initiate HyPe object\n",
    "hyp3 = sdk.HyP3(prompt = True)\n",
    "insar_jobs = sdk.Batch()\n",
    "\n",
    "# submit InSAR jobs\n",
    "for i, secondary_granule in enumerate(secondary_granules):\n",
    "    gen_geometry = i == 0\n",
    "    insar_jobs += hyp3.submit_insar_job(reference_granule,\n",
    "                                        secondary_granule,\n",
    "                                        name=projectname,\n",
    "                                        include_inc_map=gen_geometry,\n",
    "                                        include_dem=gen_geometry)\n",
    "\n",
    "# watch InSAR jobs\n",
    "insar_jobs = hyp3.watch(insar_jobs)\n",
    "\n",
    "# download and uncompress InSAR results\n",
    "zip_files = insar_jobs.download_files()\n",
    "\n",
    "for zip_file in zip_files:\n",
    "    with zipfile.ZipFile(zip_file) as zip_ref:\n",
    "        zip_ref.extractall(hyp3_dir)\n",
    "\n",
    "# prepared data structure are:\n",
    "! tree {hyp3_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare InSAR files for MintPy time series analysis\n",
    "\n",
    "By clipping the GeoTIFF files into the same grids using `gdal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob.glob(os.path.join(hyp3_dir, '*/*.tif'))\n",
    "\n",
    "# determine the smallest area covered by all input files\n",
    "corners = [gdal.Info(f, format='json')['cornerCoordinates'] for f in fnames]\n",
    "ulx = max(corner['upperLeft'][0] for corner in corners)\n",
    "uly = min(corner['upperLeft'][1] for corner in corners)\n",
    "lrx = min(corner['lowerRight'][0] for corner in corners)\n",
    "lry = max(corner['lowerRight'][1] for corner in corners)\n",
    "\n",
    "# subset all input files to these common coordinates\n",
    "for fname in fnames:\n",
    "    fname_out = fname.replace('.tif', '_clip.tif')\n",
    "    gdal.Translate(destName=fname_out, srcDS=fname, projWin=[ulx, uly, lrx, lry])\n",
    "\n",
    "# show the data structure\n",
    "! tree {hyp3_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run MintPy routine workflow `smallbaselineApp.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Prepare the template file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_txt = f'''\n",
    "mintpy.load.processor        = hyp3\n",
    "##---------interferogram datasets:\n",
    "mintpy.load.unwFile          = {hyp3_dir}/*/*unw_phase_clip.tif\n",
    "mintpy.load.corFile          = {hyp3_dir}/*/*corr_clip.tif\n",
    "##---------geometry datasets:\n",
    "mintpy.load.demFile          = {hyp3_dir}/*/*dem_clip.tif\n",
    "mintpy.load.incAngleFile     = {hyp3_dir}/*/*inc_map_clip.tif\n",
    "'''\n",
    "\n",
    "# write to file\n",
    "config_file = os.path.join(mintpy_dir, f'{proj_name}.txt')\n",
    "with open(config_file, 'w') as fid:\n",
    "    fid.write(config_txt)\n",
    "print('write file:', config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Run Time-series Analysis application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! smallbaselineApp.py {config_file} --work-dir {mintpy_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Display the analysis results\n",
    "\n",
    "There are a few scripts used to display the analysis results. There are in the MINTPY_HOME/mintpy. Here we show two majoy disaply scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.main(['mintpy/velocity.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsview.main(['mintpy/timeseries.h5'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
